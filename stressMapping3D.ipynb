{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def init_graph(G,node_adj_frame):\n",
    "#     G.add_nodes_from([i for i in range(len(node_adj_frame))])\n",
    "#     labels = {}\n",
    "#     labels = node_adj_frame.columns\n",
    "#     for i in range(len(node_adj_frame)):\n",
    "#         snode = -1\n",
    "#         if node_adj_frame[labels[0]][i] < 81:\n",
    "#             snode= node_adj_frame[labels[0]][i]-1 #s.no.\n",
    "#         else:\n",
    "#             snode= node_adj_frame[labels[0]][i]-2\n",
    "#         temp = node_adj_frame[labels[2]][i]\n",
    "#         if ',' in str(temp):\n",
    "#             sedge_arr = temp.split(',')\n",
    "#             for j in range(0, len(sedge_arr)):\n",
    "#                 k = int(sedge_arr[j])\n",
    "#                 if k < 81:\n",
    "#                     G.add_edge(snode, k-1)\n",
    "#                 else:\n",
    "#                     G.add_edge(snode, k-2)\n",
    "#         elif temp == np.nan:\n",
    "#             print(\"ERROR: Not found in the adjacency excel sheet\")\n",
    "#         else:\n",
    "#             G.add_edge(snode, int(temp)-1)\n",
    "#     return\n",
    "\n",
    "def init_graph(G,node_adj_frame):\n",
    "    G.add_nodes_from([i for i in range(len(node_adj_frame))])\n",
    "    labels = {}\n",
    "    labels = node_adj_frame.columns\n",
    "    for i in range(len(node_adj_frame)):\n",
    "        snode = node_adj_frame[labels[0]][i]-1\n",
    "        if snode == 80:\n",
    "            continue\n",
    "        temp = node_adj_frame[labels[2]][i]\n",
    "        if ',' in str(temp):\n",
    "            sedge_arr = temp.split(',')\n",
    "            for j in range(0, len(sedge_arr)):\n",
    "                k = int(sedge_arr[j])\n",
    "                G.add_edge(snode, k-1)\n",
    "        elif np.isnan(temp):\n",
    "            print(\"ERROR: Not found in the adjacency excel sheet\")\n",
    "        else:\n",
    "            G.add_edge(snode, int(temp)-1)\n",
    "    G.remove_node(80)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def init_graph_attr(G,AdjFile,df,col1,col2, col3):\n",
    "#     node_adj_frame = pd.read_excel(AdjFile)\n",
    "#     node_list = node_adj_frame[\"KGISTalukN\"].tolist()\n",
    "#     nodeAttr = {}\n",
    "#     init_graph(G,node_adj_frame)\n",
    "#     capability_vector = list(zip(df[col1],df[col2],df[col3]))\n",
    "#     node_attri_dict = dict(zip(df[\"Taluka\"],capability_vector))\n",
    "#     node_attri_dict = dict((k.lower(), v) for k, v in node_attri_dict.items())\n",
    "#     for i in range(len(node_adj_frame)):\n",
    "#         temp = {}\n",
    "#         temp[\"capabilityvector\"] = node_attri_dict[node_list[i].lower()]\n",
    "#         temp[\"nodeStress\"] = 0\n",
    "#         temp[\"name\"] = node_list[i]\n",
    "#         nodeAttr[i] = temp\n",
    "#     nx.set_node_attributes(G, nodeAttr)\n",
    "\n",
    "def init_graph_attr(G,AdjFile,df,col1, col2, col3):\n",
    "    node_adj_frame = pd.read_excel(AdjFile)\n",
    "    node_list = node_adj_frame[\"KGISTalukN\"].tolist()\n",
    "    node_list.insert(80, \"\")\n",
    "    nodeAttr = {}\n",
    "    init_graph(G,node_adj_frame)\n",
    "    capability_vector = list(zip(df[col1], df[col2], df[col3]))\n",
    "    node_attri_dict = dict(zip(df[\"Taluka\"],capability_vector))\n",
    "    node_attri_dict = dict((k.lower(), v) for k, v in node_attri_dict.items())\n",
    "    for i in range(len(node_adj_frame)):\n",
    "        temp = {}\n",
    "        if i == 80:\n",
    "            continue\n",
    "        temp[\"capabilityvector\"] = node_attri_dict[node_list[i].lower()]\n",
    "        temp[\"nodeStress\"] = 0\n",
    "        temp[\"name\"] = node_list[i]\n",
    "        nodeAttr[i] = temp\n",
    "    nt = {}\n",
    "    nt[\"capabilityvector\"] = node_attri_dict[node_list[226].lower()]\n",
    "    nt[\"nodeStress\"] = 0\n",
    "    nt[\"name\"] = \"Hadagali\"\n",
    "    nodeAttr[226] = nt\n",
    "    nx.set_node_attributes(G, nodeAttr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "df = pd.read_excel('Combined3D.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_taluka_dict = defaultdict(list)\n",
    "for k, v in zip(df[\"District_GIS\"], df[\"Taluka\"]):\n",
    "    dist_taluka_dict[k].append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addList(l1,l2):\n",
    "    for i in range(len(l1)):\n",
    "        l1[i] = l1[i] + l2[i]\n",
    "    return l1\n",
    "def divList(l1,k):\n",
    "    for i in range(len(l1)):\n",
    "        l1[i] = l1[i]/k\n",
    "    return l1\n",
    "def l2_normalization(l1,l2):\n",
    "    k = 0\n",
    "    for i in range(len(l1)):\n",
    "        k+= (l1[i] - l2[i])**2\n",
    "    return math.sqrt(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_stress(G):\n",
    "    taluka_stress_dict = {}\n",
    "    for n in G.nodes():\n",
    "        centroid = [0,0,0]\n",
    "        neighList = list(G.neighbors(n))\n",
    "        for nei in neighList:\n",
    "            try:\n",
    "                centroid = addList(centroid,list(G.nodes[nei][\"capabilityvector\"]))\n",
    "            except(KeyError):\n",
    "                pass\n",
    "        try:\n",
    "            # divide by 3?\n",
    "            G.nodes[n][\"nodeStress\"] = l2_normalization(divList(centroid,len(neighList)),list(G.nodes[n][\"capabilityvector\"]))\n",
    "        except(KeyError):\n",
    "            pass\n",
    "        try:\n",
    "            taluka_stress_dict[G.nodes[n][\"name\"].lower()]=G.nodes[n][\"nodeStress\"]\n",
    "        except(KeyError):\n",
    "            pass\n",
    "    return taluka_stress_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Taluka'] = df['Taluka'].apply(str.lower)\n",
    "init_graph_attr(G, 'IMR_Stress_AdjFile.xlsx', df, \"Normalized MMR\", \"Normalized IMR\", \"Normalized PAW\")\n",
    "initialstress = get_node_stress(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Initial Stress\"] = df[\"Taluka\"].map(initialstress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_graph_attr(G, 'IMR_Stress_AdjFile.xlsx', df, \"Normalized IMR (Kuchha Houses-20%)\", \"Normalized MMR (HM -20%)\", \"Normalized PAW (HM-20%)\")\n",
    "KHminus20stress = get_node_stress(G)\n",
    "df[\"Stress(KH-20%)\"] = df[\"Taluka\"].map(KHminus20stress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_graph_attr(G, 'IMR_Stress_AdjFile.xlsx', df, \"Normalized IMR (Kuchha Houses-10%)\", \"Normalized MMR (HM -10%)\", \"Normalized PAW (HM-10%)\")\n",
    "KHminus10stress = get_node_stress(G)\n",
    "df[\"Stress(KH-10%)\"] = df[\"Taluka\"].map(KHminus10stress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_graph_attr(G, 'IMR_Stress_AdjFile.xlsx', df, \"Normalized IMR (Kuchha Houses+10%)\", \"Normalized MMR (HM +10%)\", \"Normalized PAW (HM+10%)\")\n",
    "KHplus10stress = get_node_stress(G)\n",
    "df[\"Stress(KH+10%)\"] = df[\"Taluka\"].map(KHplus10stress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_graph_attr(G, 'IMR_Stress_AdjFile.xlsx', df, \"Normalized IMR (Kuchha Houses+20%)\", \"Normalized MMR (HM +20%)\", \"Normalized PAW (HM+20%)\")\n",
    "KHplus20stress = get_node_stress(G)\n",
    "df[\"Stress(KH+20%)\"] = df[\"Taluka\"].map(KHplus20stress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"3D_StressFile.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(taluka_stress_dict):\n",
    "    dist_stress = {}\n",
    "    for dist, taluks in dist_taluka_dict.items():\n",
    "        agg_stress = 0\n",
    "        for taluk in taluks:\n",
    "            try:\n",
    "                agg_stress = agg_stress + taluka_stress_dict[taluk.lower()]\n",
    "            except(KeyError):\n",
    "                pass\n",
    "        dist_stress[dist] = agg_stress/len(taluks)\n",
    "    return dist_stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = pd.read_excel('3d_Impact_scaled.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_Impact_HM = pd.DataFrame()\n",
    "aggregate_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================FOR HM -20%==============================================================\n",
    "# Getting the graph ready for HM -20%\n",
    "init_graph_attr(G, 'IMR_Stress_AdjFile.xlsx', df, \"Normalized IMR (Kuchha Houses-20%)\", \"Normalized MMR (HM -20%)\", \"Normalized PAW (HM-20%)\")\n",
    "\n",
    "# These dict have the names vs Impact Score for HM -20%\n",
    "IMR_impact_dict = dict(zip(df_imp[\"Taluka\"],df_imp[\"IMR HI -20% | Impact\"]))\n",
    "MMR_impact_dict = dict(zip(df_imp[\"Taluka\"],df_imp[\"MMR HI -20% | Impact\"]))\n",
    "PAW_impact_dict = dict(zip(df_imp[\"Taluka\"],df_imp[\"PAW HI -20% | Impact\"]))\n",
    "\n",
    "# Here, we are just converting the taluka names in these dictionaries to lower case\n",
    "# IMR_impact_dict= dict((k.lower(), v) for k, v in IMR_impact_dict.items())\n",
    "# MMR_impact_dict= dict((k.lower(), v) for k, v in MMR_impact_dict.items())\n",
    "# PAW_impact_dict= dict((k.lower(), v) for k, v in PAW_impact_dict.items())\n",
    "\n",
    "# Aggregating both the impacts\n",
    "aggregate_IMR_Impact = aggregate(IMR_impact_dict)\n",
    "aggregate_MMR_Impact = aggregate(MMR_impact_dict)\n",
    "aggregate_PAW_Impact = aggregate(PAW_impact_dict)\n",
    "\n",
    "# Aggregating the stress\n",
    "aggregate_Stress = aggregate(get_node_stress(G))\n",
    "\n",
    "# Putting it in a temp df\n",
    "temp2_df = pd.DataFrame.from_dict([aggregate_IMR_Impact, aggregate_MMR_Impact, aggregate_PAW_Impact, aggregate_Stress])\n",
    "aI_df = temp2_df.T\n",
    "aI_df = temp2_df.transpose()\n",
    "aI_df.rename(columns = {0:'IMPACT_SCORE_IMR (HM - 20%)', 1:'IMPACT_SCORE_MMR (HM - 20%)', 2:'IMPACT_SCORE_PAW (HM - 20%)', 3:'STRESS_SCORE (HM -20%)'}, inplace = True)\n",
    "aggregate_df = aI_df\n",
    "\n",
    "# Now, we are converting them into a dataframe and making them Taluka, Impact, Stress\n",
    "combined_IMR = pd.DataFrame.from_dict([IMR_impact_dict, get_node_stress(G)])\n",
    "combined_MMR = pd.DataFrame.from_dict([MMR_impact_dict, get_node_stress(G)])\n",
    "combined_PAW = pd.DataFrame.from_dict([MMR_impact_dict, get_node_stress(G)])\n",
    "\n",
    "# Now, we are taking a transpose, so that we get it in column form\n",
    "trdIMR = combined_IMR.T\n",
    "trdMMR = combined_MMR.T\n",
    "trdPAW = combined_PAW.T\n",
    "trdIMR = combined_IMR.transpose()\n",
    "trdMMR = combined_MMR.transpose()\n",
    "trdPAW = combined_PAW.transpose()\n",
    "\n",
    "# Renaming the columns\n",
    "trdIMR.rename(columns = {0:'IMPACT_SCORE_IMR (HM - 20%)', 1:'STRESS_SCORE (HM -20%)'}, inplace = True)\n",
    "trdMMR.rename(columns = {0:'IMPACT_SCORE_MMR (HM - 20%)', 1:'STRESS_SCORE (HM -20%)'}, inplace = True)\n",
    "trdPAW.rename(columns = {0:'IMPACT_SCORE_PAW (HM - 20%)', 1:'STRESS_SCORE (HM -20%)'}, inplace = True)\n",
    "\n",
    "# Filling the dataframe\n",
    "combined_Impact_HM = trdIMR\n",
    "combined_Impact_HM['IMPACT_SCORE_MMR (HM - 20%)'] = trdMMR['IMPACT_SCORE_MMR (HM - 20%)']\n",
    "combined_Impact_HM['IMPACT_SCORE_PAW (HM - 20%)'] = trdPAW['IMPACT_SCORE_PAW (HM - 20%)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMPACT_SCORE_IMR (HM - 20%)</th>\n",
       "      <th>IMPACT_SCORE_MMR (HM - 20%)</th>\n",
       "      <th>IMPACT_SCORE_PAW (HM - 20%)</th>\n",
       "      <th>STRESS_SCORE (HM -20%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kalburgi</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chikkamagaluru</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dharwad</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hassan</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bengaluru_Urban</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uttara_Kannada</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.275251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belagavi</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bidar</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vijayapura</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.186678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagalkot</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chikkaballapura</th>\n",
       "      <td>0.214344</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.219779</td>\n",
       "      <td>0.465698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ballari</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.289832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kolara</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dakshina_Kannada</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shivamogga</th>\n",
       "      <td>0.225632</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.095581</td>\n",
       "      <td>0.240387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Udupi</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haveri</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chitradurga</th>\n",
       "      <td>0.424594</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.227867</td>\n",
       "      <td>0.271794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chamarajanagara</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.401948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Davanagere</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.398984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ramanagara</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tumakuru</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bengaluru_Rural</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raichur</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.348140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gadag</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.330011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Koppal</th>\n",
       "      <td>0.107531</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.088293</td>\n",
       "      <td>0.275669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yadgir</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mysuru</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.326691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mandya</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kodagu</th>\n",
       "      <td>0.179299</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.124178</td>\n",
       "      <td>0.240888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  IMPACT_SCORE_IMR (HM - 20%)  IMPACT_SCORE_MMR (HM - 20%)  \\\n",
       "Kalburgi                             0.000000                     0.000000   \n",
       "Chikkamagaluru                       0.000000                     0.000000   \n",
       "Dharwad                              0.000000                     0.000000   \n",
       "Hassan                               0.000000                     0.000000   \n",
       "Bengaluru_Urban                      0.000000                     0.000000   \n",
       "Uttara_Kannada                       0.000000                     0.000000   \n",
       "Belagavi                             0.000000                     0.000000   \n",
       "Bidar                                0.000000                     0.000000   \n",
       "Vijayapura                           0.000000                     0.000000   \n",
       "Bagalkot                             0.000000                     0.000000   \n",
       "Chikkaballapura                      0.214344                     0.000945   \n",
       "Ballari                              0.000000                     0.000000   \n",
       "Kolara                               0.000000                     0.000000   \n",
       "Dakshina_Kannada                     0.000000                     0.000000   \n",
       "Shivamogga                           0.225632                     0.000994   \n",
       "Udupi                                0.000000                     0.000000   \n",
       "Haveri                               0.000000                     0.000000   \n",
       "Chitradurga                          0.424594                     0.001871   \n",
       "Chamarajanagara                      0.000000                     0.000000   \n",
       "Davanagere                           0.000000                     0.000000   \n",
       "Ramanagara                           0.000000                     0.000000   \n",
       "Tumakuru                             0.000000                     0.000000   \n",
       "Bengaluru_Rural                      0.000000                     0.000000   \n",
       "Raichur                              0.000000                     0.000000   \n",
       "Gadag                                0.000000                     0.000000   \n",
       "Koppal                               0.107531                     0.000474   \n",
       "Yadgir                               0.000000                     0.000000   \n",
       "Mysuru                               0.000000                     0.000000   \n",
       "Mandya                               0.000000                     0.000000   \n",
       "Kodagu                               0.179299                     0.000790   \n",
       "\n",
       "                  IMPACT_SCORE_PAW (HM - 20%)  STRESS_SCORE (HM -20%)  \n",
       "Kalburgi                             0.000000                0.285752  \n",
       "Chikkamagaluru                       0.000000                0.325016  \n",
       "Dharwad                              0.000000                0.397946  \n",
       "Hassan                               0.000000                0.397411  \n",
       "Bengaluru_Urban                      0.000000                0.209030  \n",
       "Uttara_Kannada                       0.000000                0.275251  \n",
       "Belagavi                             0.000000                0.218534  \n",
       "Bidar                                0.000000                0.231000  \n",
       "Vijayapura                           0.000000                0.186678  \n",
       "Bagalkot                             0.000000                0.287923  \n",
       "Chikkaballapura                      0.219779                0.465698  \n",
       "Ballari                              0.000000                0.289832  \n",
       "Kolara                               0.000000                0.231873  \n",
       "Dakshina_Kannada                     0.000000                0.163082  \n",
       "Shivamogga                           0.095581                0.240387  \n",
       "Udupi                                0.000000                0.194321  \n",
       "Haveri                               0.000000                0.259761  \n",
       "Chitradurga                          0.227867                0.271794  \n",
       "Chamarajanagara                      0.000000                0.401948  \n",
       "Davanagere                           0.000000                0.398984  \n",
       "Ramanagara                           0.000000                0.384405  \n",
       "Tumakuru                             0.000000                0.315585  \n",
       "Bengaluru_Rural                      0.000000                0.305020  \n",
       "Raichur                              0.000000                0.348140  \n",
       "Gadag                                0.000000                0.330011  \n",
       "Koppal                               0.088293                0.275669  \n",
       "Yadgir                               0.000000                0.380115  \n",
       "Mysuru                               0.000000                0.326691  \n",
       "Mandya                               0.000000                0.353909  \n",
       "Kodagu                               0.124178                0.240888  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================FOR HM -10%==============================================================\n",
    "# Getting the graph ready for HM -10%\n",
    "init_graph_attr(G, 'IMR_Stress_AdjFile.xlsx', df, \"Normalized IMR (Kuchha Houses-10%)\", \"Normalized MMR (HM -10%)\", \"Normalized PAW (HM-10%)\")\n",
    "\n",
    "# These dict have the names vs Impact Score for HM -10%\n",
    "IMR_impact_dict = dict(zip(df_imp[\"Taluka\"],df_imp[\"IMR HI -10% | Impact\"]))\n",
    "MMR_impact_dict = dict(zip(df_imp[\"Taluka\"],df_imp[\"MMR HI -10% | Impact\"]))\n",
    "PAW_impact_dict = dict(zip(df_imp[\"Taluka\"],df_imp[\"PAW HI -10% | Impact\"]))\n",
    "\n",
    "# Here, we are just converting the taluka names in these dictionaries to lower case\n",
    "IMR_impact_dict= dict((k.lower(), v) for k, v in IMR_impact_dict.items())\n",
    "MMR_impact_dict= dict((k.lower(), v) for k, v in MMR_impact_dict.items())\n",
    "PAW_impact_dict= dict((k.lower(), v) for k, v in PAW_impact_dict.items())\n",
    "\n",
    "# Aggregating both the impacts\n",
    "aggregate_IMR_Impact = aggregate(IMR_impact_dict)\n",
    "aggregate_MMR_Impact = aggregate(MMR_impact_dict)\n",
    "aggregate_PAW_Impact = aggregate(PAW_impact_dict)\n",
    "\n",
    "# Aggregating the stress\n",
    "aggregate_Stress = aggregate(get_node_stress(G))\n",
    "\n",
    "# Putting it in a temp df\n",
    "temp2_df = pd.DataFrame.from_dict([aggregate_IMR_Impact, aggregate_MMR_Impact, aggregate_PAW_Impact, aggregate_Stress])\n",
    "aI_df = temp2_df.T\n",
    "aI_df = temp2_df.transpose()\n",
    "aI_df.rename(columns = {0:'IMPACT_SCORE_IMR (HM - 10%)', 1:'IMPACT_SCORE_MMR (HM - 10%)', 2:'IMPACT_SCORE_PAW (HM - 10%)', 3:'STRESS_SCORE (HM -10%)'}, inplace = True)\n",
    "aggregate_df['IMPACT_SCORE_IMR (HM - 10%)'] = aI_df['IMPACT_SCORE_IMR (HM - 10%)']\n",
    "aggregate_df['IMPACT_SCORE_MMR (HM - 10%)'] = aI_df['IMPACT_SCORE_MMR (HM - 10%)']\n",
    "aggregate_df['IMPACT_SCORE_PAW (HM - 10%)'] = aI_df['IMPACT_SCORE_PAW (HM - 10%)']\n",
    "aggregate_df['STRESS_SCORE (HM -10%)'] = aI_df['STRESS_SCORE (HM -10%)']\n",
    "\n",
    "# Now, we are converting them into a dataframe and making them Taluka, Impact, Stress\n",
    "combined_IMR = pd.DataFrame.from_dict([IMR_impact_dict, get_node_stress(G)])\n",
    "combined_MMR = pd.DataFrame.from_dict([MMR_impact_dict, get_node_stress(G)])\n",
    "combined_PAW = pd.DataFrame.from_dict([MMR_impact_dict, get_node_stress(G)])\n",
    "\n",
    "# Now, we are taking a transpose, so that we get it in column form\n",
    "trdIMR = combined_IMR.T\n",
    "trdMMR = combined_MMR.T\n",
    "trdPAW = combined_PAW.T\n",
    "trdIMR = combined_IMR.transpose()\n",
    "trdMMR = combined_MMR.transpose()\n",
    "trdPAW = combined_PAW.transpose()\n",
    "\n",
    "# Renaming the columns\n",
    "trdIMR.rename(columns = {0:'IMPACT_SCORE_IMR (HM - 10%)', 1:'STRESS_SCORE (HM -10%)'}, inplace = True)\n",
    "trdMMR.rename(columns = {0:'IMPACT_SCORE_MMR (HM - 10%)', 1:'STRESS_SCORE (HM -10%)'}, inplace = True)\n",
    "trdPAW.rename(columns = {0:'IMPACT_SCORE_PAW (HM - 10%)', 1:'STRESS_SCORE (HM -10%)'}, inplace = True)\n",
    "\n",
    "# Filling the dataframe\n",
    "combined_Impact_HM['STRESS_SCORE (HM -10%)'] = trdPAW['STRESS_SCORE (HM -10%)']\n",
    "combined_Impact_HM['IMPACT_SCORE_IMR (HM - 10%)'] = trdIMR['IMPACT_SCORE_IMR (HM - 10%)']\n",
    "combined_Impact_HM['IMPACT_SCORE_MMR (HM - 10%)'] = trdMMR['IMPACT_SCORE_MMR (HM - 10%)']\n",
    "combined_Impact_HM['IMPACT_SCORE_PAW (HM - 10%)'] = trdPAW['IMPACT_SCORE_PAW (HM - 10%)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================FOR HM +10%==============================================================\n",
    "# Getting the graph ready for HM +10%\n",
    "init_graph_attr(G, 'IMR_Stress_AdjFile.xlsx', df, \"Normalized IMR (Kuchha Houses+10%)\", \"Normalized MMR (HM +10%)\", \"Normalized PAW (HM+10%)\")\n",
    "\n",
    "# These dict have the names vs Impact Score for HM +10%\n",
    "IMR_impact_dict = dict(zip(df_imp[\"Taluka\"],df_imp[\"IMR HI +10% | Impact\"]))\n",
    "MMR_impact_dict = dict(zip(df_imp[\"Taluka\"],df_imp[\"MMR HI +10% | Impact\"]))\n",
    "PAW_impact_dict = dict(zip(df_imp[\"Taluka\"],df_imp[\"PAW HI +10% | Impact\"]))\n",
    "\n",
    "# Here, we are just converting the taluka names in these dictionaries to lower case\n",
    "IMR_impact_dict= dict((k.lower(), v) for k, v in IMR_impact_dict.items())\n",
    "MMR_impact_dict= dict((k.lower(), v) for k, v in MMR_impact_dict.items())\n",
    "PAW_impact_dict= dict((k.lower(), v) for k, v in PAW_impact_dict.items())\n",
    "\n",
    "# Aggregating both the impacts\n",
    "aggregate_IMR_Impact = aggregate(IMR_impact_dict)\n",
    "aggregate_MMR_Impact = aggregate(MMR_impact_dict)\n",
    "aggregate_PAW_Impact = aggregate(PAW_impact_dict)\n",
    "\n",
    "# Aggregating the stress\n",
    "aggregate_Stress = aggregate(get_node_stress(G))\n",
    "\n",
    "# Putting it in a temp df\n",
    "temp2_df = pd.DataFrame.from_dict([aggregate_IMR_Impact, aggregate_MMR_Impact, aggregate_PAW_Impact, aggregate_Stress])\n",
    "aI_df = temp2_df.T\n",
    "aI_df = temp2_df.transpose()\n",
    "aI_df.rename(columns = {0:'IMPACT_SCORE_IMR (HM + 10%)', 1:'IMPACT_SCORE_MMR (HM + 10%)', 2:'IMPACT_SCORE_PAW (HM + 10%)', 3:'STRESS_SCORE (HM +10%)'}, inplace = True)\n",
    "aggregate_df['IMPACT_SCORE_IMR (HM + 10%)'] = aI_df['IMPACT_SCORE_IMR (HM + 10%)']\n",
    "aggregate_df['IMPACT_SCORE_MMR (HM + 10%)'] = aI_df['IMPACT_SCORE_MMR (HM + 10%)']\n",
    "aggregate_df['IMPACT_SCORE_PAW (HM + 10%)'] = aI_df['IMPACT_SCORE_PAW (HM + 10%)']\n",
    "aggregate_df['STRESS_SCORE (HM +10%)'] = aI_df['STRESS_SCORE (HM +10%)']\n",
    "\n",
    "# Now, we are converting them into a dataframe and making them Taluka, Impact, Stress\n",
    "combined_IMR = pd.DataFrame.from_dict([IMR_impact_dict, get_node_stress(G)])\n",
    "combined_MMR = pd.DataFrame.from_dict([MMR_impact_dict, get_node_stress(G)])\n",
    "combined_PAW = pd.DataFrame.from_dict([MMR_impact_dict, get_node_stress(G)])\n",
    "\n",
    "# Now, we are taking a transpose, so that we get it in column form\n",
    "trdIMR = combined_IMR.T\n",
    "trdMMR = combined_MMR.T\n",
    "trdPAW = combined_PAW.T\n",
    "trdIMR = combined_IMR.transpose()\n",
    "trdMMR = combined_MMR.transpose()\n",
    "trdPAW = combined_PAW.transpose()\n",
    "\n",
    "# Renaming the columns\n",
    "trdIMR.rename(columns = {0:'IMPACT_SCORE_IMR (HM + 10%)', 1:'STRESS_SCORE (HM +10%)'}, inplace = True)\n",
    "trdMMR.rename(columns = {0:'IMPACT_SCORE_MMR (HM + 10%)', 1:'STRESS_SCORE (HM +10%)'}, inplace = True)\n",
    "trdPAW.rename(columns = {0:'IMPACT_SCORE_PAW (HM + 10%)', 1:'STRESS_SCORE (HM +10%)'}, inplace = True)\n",
    "\n",
    "# Filling the dataframe\n",
    "combined_Impact_HM['STRESS_SCORE (HM +10%)'] = trdPAW['STRESS_SCORE (HM +10%)']\n",
    "combined_Impact_HM['IMPACT_SCORE_IMR (HM + 10%)'] = trdIMR['IMPACT_SCORE_IMR (HM + 10%)']\n",
    "combined_Impact_HM['IMPACT_SCORE_MMR (HM + 10%)'] = trdMMR['IMPACT_SCORE_MMR (HM + 10%)']\n",
    "combined_Impact_HM['IMPACT_SCORE_PAW (HM + 10%)'] = trdPAW['IMPACT_SCORE_PAW (HM + 10%)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================FOR HM +20%==============================================================\n",
    "# Getting the graph ready for HM +20%\n",
    "init_graph_attr(G, 'IMR_Stress_AdjFile.xlsx', df, \"Normalized IMR (Kuchha Houses+20%)\", \"Normalized MMR (HM +20%)\", \"Normalized PAW (HM+20%)\")\n",
    "\n",
    "# These dict have the names vs Impact Score for HM +20%\n",
    "IMR_impact_dict = dict(zip(df_imp[\"Taluka\"],df_imp[\"IMR HI +20% | Impact\"]))\n",
    "MMR_impact_dict = dict(zip(df_imp[\"Taluka\"],df_imp[\"MMR HI +20% | Impact\"]))\n",
    "PAW_impact_dict = dict(zip(df_imp[\"Taluka\"],df_imp[\"PAW HI +20% | Impact\"]))\n",
    "\n",
    "# Here, we are just converting the taluka names in these dictionaries to lower case\n",
    "IMR_impact_dict= dict((k.lower(), v) for k, v in IMR_impact_dict.items())\n",
    "MMR_impact_dict= dict((k.lower(), v) for k, v in MMR_impact_dict.items())\n",
    "PAW_impact_dict= dict((k.lower(), v) for k, v in PAW_impact_dict.items())\n",
    "\n",
    "# Aggregating both the impacts\n",
    "aggregate_IMR_Impact = aggregate(IMR_impact_dict)\n",
    "aggregate_MMR_Impact = aggregate(MMR_impact_dict)\n",
    "aggregate_PAW_Impact = aggregate(PAW_impact_dict)\n",
    "\n",
    "# Aggregating the stress\n",
    "aggregate_Stress = aggregate(get_node_stress(G))\n",
    "\n",
    "# Putting it in a temp df\n",
    "temp2_df = pd.DataFrame.from_dict([aggregate_IMR_Impact, aggregate_MMR_Impact, aggregate_PAW_Impact, aggregate_Stress])\n",
    "aI_df = temp2_df.T\n",
    "aI_df = temp2_df.transpose()\n",
    "aI_df.rename(columns = {0:'IMPACT_SCORE_IMR (HM + 20%)', 1:'IMPACT_SCORE_MMR (HM + 20%)', 2:'IMPACT_SCORE_PAW (HM + 20%)', 3:'STRESS_SCORE (HM +20%)'}, inplace = True)\n",
    "aggregate_df['IMPACT_SCORE_IMR (HM + 20%)'] = aI_df['IMPACT_SCORE_IMR (HM + 20%)']\n",
    "aggregate_df['IMPACT_SCORE_MMR (HM + 20%)'] = aI_df['IMPACT_SCORE_MMR (HM + 20%)']\n",
    "aggregate_df['IMPACT_SCORE_PAW (HM + 20%)'] = aI_df['IMPACT_SCORE_PAW (HM + 20%)']\n",
    "aggregate_df['STRESS_SCORE (HM +20%)'] = aI_df['STRESS_SCORE (HM +20%)']\n",
    "\n",
    "# Now, we are converting them into a dataframe and making them Taluka, Impact, Stress\n",
    "combined_IMR = pd.DataFrame.from_dict([IMR_impact_dict, get_node_stress(G)])\n",
    "combined_MMR = pd.DataFrame.from_dict([MMR_impact_dict, get_node_stress(G)])\n",
    "combined_PAW = pd.DataFrame.from_dict([MMR_impact_dict, get_node_stress(G)])\n",
    "\n",
    "# Now, we are taking a transpose, so that we get it in column form\n",
    "trdIMR = combined_IMR.T\n",
    "trdMMR = combined_MMR.T\n",
    "trdPAW = combined_PAW.T\n",
    "trdIMR = combined_IMR.transpose()\n",
    "trdMMR = combined_MMR.transpose()\n",
    "trdPAW = combined_PAW.transpose()\n",
    "\n",
    "# Renaming the columns\n",
    "trdIMR.rename(columns = {0:'IMPACT_SCORE_IMR (HM + 20%)', 1:'STRESS_SCORE (HM +20%)'}, inplace = True)\n",
    "trdMMR.rename(columns = {0:'IMPACT_SCORE_MMR (HM + 20%)', 1:'STRESS_SCORE (HM +20%)'}, inplace = True)\n",
    "trdPAW.rename(columns = {0:'IMPACT_SCORE_PAW (HM + 20%)', 1:'STRESS_SCORE (HM +20%)'}, inplace = True)\n",
    "\n",
    "# Filling the dataframe\n",
    "combined_Impact_HM['STRESS_SCORE (HM +20%)'] = trdPAW['STRESS_SCORE (HM +20%)']\n",
    "combined_Impact_HM['IMPACT_SCORE_IMR (HM + 20%)'] = trdIMR['IMPACT_SCORE_IMR (HM + 20%)']\n",
    "combined_Impact_HM['IMPACT_SCORE_MMR (HM + 20%)'] = trdMMR['IMPACT_SCORE_MMR (HM + 20%)']\n",
    "combined_Impact_HM['IMPACT_SCORE_PAW (HM + 20%)'] = trdPAW['IMPACT_SCORE_PAW (HM + 20%)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_df.to_excel('Scaled_3D_tableau.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
